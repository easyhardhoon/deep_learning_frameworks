{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM0vb5qpq4ssN8a3NPefyC8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c13b66911a6485eb78bc5b618c14f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_209abe57e5fb465ba2780f617fa29413",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b8ae76a603d04afb88634482fa5834c8",
              "IPY_MODEL_0640f0eb525548b3a0e800fa91684fc3",
              "IPY_MODEL_1c1212508d9045318fa0b320167a9f0e"
            ]
          }
        },
        "209abe57e5fb465ba2780f617fa29413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8ae76a603d04afb88634482fa5834c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_230738751f094c81b7fb0b8ee9d0757a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a456242ef4c44f50b0da24d27de7869f"
          }
        },
        "0640f0eb525548b3a0e800fa91684fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3ff459389d27444d8893daf0bf5844f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd47932de5524cc5a810f7cdaf9fc066"
          }
        },
        "1c1212508d9045318fa0b320167a9f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f6cc2138f113495a8129ef147e7094f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:04&lt;00:00, 41070495.73it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ed4dfcaa20c4e5d83036e4d23aa12a0"
          }
        },
        "230738751f094c81b7fb0b8ee9d0757a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a456242ef4c44f50b0da24d27de7869f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ff459389d27444d8893daf0bf5844f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd47932de5524cc5a810f7cdaf9fc066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6cc2138f113495a8129ef147e7094f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ed4dfcaa20c4e5d83036e4d23aa12a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/easyhardhoon/deep_learning_frameworks/blob/main/Pytorch4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch3에 대한 복습입니다\n",
        "\n",
        "✈데이터 불러오기 방법 3가지\n",
        "\n",
        "    어떤 방법이든 \n",
        "\n",
        "    데이터 전처리 + DataLoader배치조정 의 형태는 동일합니다"
      ],
      "metadata": {
        "id": "WDjj4QT-QeGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as tr\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ebnrvsx3eNTm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. 파이토치 제공 데이터 사용**"
      ],
      "metadata": {
        "id": "hvGfSW2TeNCO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "0c13b66911a6485eb78bc5b618c14f15",
            "209abe57e5fb465ba2780f617fa29413",
            "b8ae76a603d04afb88634482fa5834c8",
            "0640f0eb525548b3a0e800fa91684fc3",
            "1c1212508d9045318fa0b320167a9f0e",
            "230738751f094c81b7fb0b8ee9d0757a",
            "a456242ef4c44f50b0da24d27de7869f",
            "3ff459389d27444d8893daf0bf5844f0",
            "bd47932de5524cc5a810f7cdaf9fc066",
            "f6cc2138f113495a8129ef147e7094f5",
            "7ed4dfcaa20c4e5d83036e4d23aa12a0"
          ]
        },
        "id": "4Tdw1ZqCQaV4",
        "outputId": "a9bcccc3-67b1-4fae-bfdf-a33d05742970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c13b66911a6485eb78bc5b618c14f15",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "transf = tr.Compose([tr.Resize(8), tr.ToTensor()])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train= True, download = True, transform=transf)\n",
        "trainloader = DataLoader(trainset,batch_size=50,shuffle=True,num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. 같은 클래스 별 폴더 이미지 데이터 이용**"
      ],
      "metadata": {
        "id": "_J5wGItbfLfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#./class/tiger, ./class/lion 와 같이 class 하위 폴더에 각각의 데이터 폴더가 있을때\n",
        "transf = tr.Compose([tr.Resize(16), tr.ToTensor()])\n",
        "trainset = torchvision.datasets.ImageFolder(root='./class', transform=transf)\n",
        "trainloader = DataLoader(trainset,batch_size=1,shuffle=False,num_workers=2)"
      ],
      "metadata": {
        "id": "IXfEcu71e-7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1 개인 데이터 사용(transform 도움없이)**"
      ],
      "metadata": {
        "id": "zPYEaMt0gHR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = np.random.randint(256,size=(20,32,32,3))\n",
        "train_labels = np.random.randint(2,size=(20,1))\n",
        "#import preprocessing\n",
        "#train_images, train_labels = preprocessing(train_images,train_labels) \n",
        "# 위 코드는 \"일련의 전처리 과정\"을 라이브러리로 만들어서 import 한것입니다. \n",
        "# 결국 수동 전처리라는 개념에서 동일하다고 생각됩니다.\n",
        "class TensorData(Dataset): #수동 전처리를 위한 클래스입니다\n",
        "  def __init__(self,x_data,y_data):\n",
        "    self.x_data = torch.FloatTensor(x_data)\n",
        "    self.x_data = self.x_data.permute(0,3,1,2) \n",
        "    self.y_data = torch.LongTensor(y_data) \n",
        "    self.len = self.y_data.shape[0] \n",
        "  def __getitem__(self,index):\n",
        "      return self.x_data[index], self.y_data[index]\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "train_data = TensorData(train_images,train_labels)\n",
        "train_loader = DataLoader(train_data, batch_size=10,shuffle=True)"
      ],
      "metadata": {
        "id": "4awod8p0fuat"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2 개인 데이터 사용(transform 도움받고)**"
      ],
      "metadata": {
        "id": "Vw5L-uFMmMfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = np.random.randint(256,size=(20,32,32,3))\n",
        "train_labels = np.random.randint(2,size=(20,1))\n",
        "class MyDataset(Dataset): \n",
        "  def __init__(self,x_data,y_data,transform=None):\n",
        "    self.x_data = x_data\n",
        "    self.y_data = y_data \n",
        "    self.transform = transform\n",
        "    self.len = len(y_data)\n",
        "  def __getitem__(self,index):\n",
        "      sample = self.x_data[index], self.y_data[index]\n",
        "      if self.transform: #transform이 활성화되면 transform의 도움을 받는다\n",
        "        sample= self.transform(sample) \n",
        "      return sample\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "class ToTensor: #tr.ToTensor를 사용할 수 없기 때문에 수동설정.\n",
        "  #이유는 데이터 타입이 현재 PIL image가 아닌 numpy이기 때문입니다.\n",
        "  def __call__(self,sample):\n",
        "    inputs, labels = sample\n",
        "    inputs = torch.FloatTensor(inputs)\n",
        "    inputs = inputs.permute(2,0,1)\n",
        "    return inputs, torch.LongTensor(labels)\n",
        "class LinearTensor:\n",
        "  def __init__(self,slope=1,bias=0):\n",
        "    self.slope = slope\n",
        "    self.bias = bias\n",
        "  def __call__(self,sample):\n",
        "    inputs,labels=sample\n",
        "    inputs= self.slope*inputs+self.bias\n",
        "    return inputs,labels\n",
        "trans = tr.Compose([ToTensor(), LinearTensor(2,5)]) \n",
        "ds1 = MyDataset(train_images,train_labels,transform=trans) \n",
        "train_loader1 = DataLoader(ds1, batch_size=10,shuffle=True) "
      ],
      "metadata": {
        "id": "xE7fksM1gzOw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3 개인 데이터 사용(transform 도움받고 & 전처리함수 수동생성 x)**"
      ],
      "metadata": {
        "id": "_lrHrdERpm1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = np.random.randint(256,size=(20,32,32,3))\n",
        "train_labels = np.random.randint(2,size=(20,1))\n",
        "class MyDataset(Dataset): \n",
        "  def __init__(self,x_data,y_data,transform=None):\n",
        "    self.x_data = x_data\n",
        "    self.y_data = y_data \n",
        "    self.transform = transform\n",
        "    self.len = len(y_data)\n",
        "  def __getitem__(self,index):\n",
        "      sample = self.x_data[index], self.y_data[index]\n",
        "      if self.transform: \n",
        "        sample= self.transform(sample) \n",
        "      return sample\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "class MyTransform:\n",
        "  def __call__(self,sample):\n",
        "    inputs, labels = sample\n",
        "    inputs = torch.FloatTensor(inputs)\n",
        "    inputs = inputs.permute(2,0,1)\n",
        "    labels = torch.FloatTensor(labels)\n",
        "    transf = tr.Compose([tr.ToPILImage(), tr.Resize(128), tr.ToTensor()]) \n",
        "    final_output = transf(inputs)\n",
        "    return final_output, labels\n",
        "ds2 = MyDataset(train_images, train_labels, transform=MyTransform())\n",
        "train_loader2 = DataLoader(ds2, batch_size=10,shuffle=True)"
      ],
      "metadata": {
        "id": "kBkZtRJemj2M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#인공신경망 구현(이미지. CNN위주)"
      ],
      "metadata": {
        "id": "cx-Pq6RIpy6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms #기본적으로 전처리를 위한 라이브러리입니다\n",
        "from torch.utils.data import DataLoader #기본적으로 배치 형태를 위한 라이브러리입니다"
      ],
      "metadata": {
        "id": "HYEq1WPRqQtV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data set(데이터 불러오기의 \"파이토치 기본 제공 데이터\"에 해당된다)**"
      ],
      "metadata": {
        "id": "76k06pZWqUoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]) #tr을 그냥 transforms라고 쓴 것 뿐. 원래 transforms의 약자가 tr이었음\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size=8,shuffle=True,num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset,batch_size=8,shuffle=False,num_workers=2)\n",
        "classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf_BHpt5qNnX",
        "outputId": "1558b83b-c36c-4624-91fa-580cd62165e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build a model**"
      ],
      "metadata": {
        "id": "BIuUdlWatcTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Net(nn.Module): #nn.Module을 상속받는다.\n",
        "  def __init__(self): #연산 세팅\n",
        "    super(Net,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,6,5) #합성곱\n",
        "    self.pool = nn.MaxPool2d(2,2) #Max풀링\n",
        "    self.conv2 = nn.Conv2d(6,16,5) #합성곱\n",
        "    self.fc1 = nn.Linear(16*5*5,120) #완전연결계층\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "  def forward(self,x): #연산 순서 세팅. 순전파\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1,16*5*5) #사이즈 변형. 완전연결계층에 연결하기 위해선 데이터를 1자로 펴야한다\n",
        "    x = F.relu(self.fc1(x)) # 단순 fc(x)는 행렬곱연산이라 생각하면 됩니다.\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "net = Net()\n"
      ],
      "metadata": {
        "id": "9sh2uO4VrWmI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#복습\n",
        "\n",
        "Fully connected layer : 완전연결 계층\n",
        "\n",
        "한층의 모든 뉴런이 다음층의 모든 뉴런과 연결된 상태.\n",
        "\n",
        "✈2차원의 배열 형태 이미지를 1차원의 평탄화 작업을 통해 이미지를 분류하는데 사용\n",
        "\n",
        "✈활성화 함수 뉴런  활성화\n",
        "\n",
        "✈분류기 함수(softmax)로 분류\n",
        "\n",
        "즉, 완전연결 계층이란\n",
        "\n",
        "**Flatten(평탄화) + 활성화함수(Relu...) + 활성화함수(softmax...)**\n",
        "\n"
      ],
      "metadata": {
        "id": "y1UA4QSo4caD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ4Dz8hC22qI",
        "outputId": "5516e911-d86b-4c14-fa83-71a7a72c2b69"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement the model with training set**"
      ],
      "metadata": {
        "id": "m4kwGNMv69Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) #net안의 parameter들을 업데이트 해주겠다는 의미\n",
        "#학습률 0.001, 근데 SGD 방식인데 momentum을 왜 쓰지..?\n",
        "\n",
        "for epoch in range(1): #epoch. 데이터 전체를 몇번 보느냐\n",
        "  running_loss = 0.0\n",
        "  for i,data in enumerate(trainloader,0): #당연히 앞에서 전처리에 배치처리까지 마친 데이터 셋이 들어가야지\n",
        "    inputs,labels=data\n",
        "    \n",
        "    optimizer.zero_grad() #파라미터의 grad값(미분값)을 0으로  초기화. \n",
        "\n",
        "    outputs= net(inputs) #산출값\n",
        "    loss = criterion(outputs,labels) #손실함수를 계산합니다. 당연히 산출값과 정답 레이블의 오차를 계산합니다 \n",
        "    #주의 : batch형태로 들어와도 loss 결과값은 무조건 스칼라값, 즉 하나의 상수 값입니다.\n",
        "    loss.backward() #역전파를 돌립니다. gradient(미분값)을 구합니다. loss 기준!!!!!\n",
        "    optimizer.step() #가중치 매개변수 값을 SGD 방식으로 업데이트 합니다.\n",
        "\n",
        "    running_loss += loss.item() #누적 loss 값을 더해줍니다. \n",
        "    if i % 2000 == 1999:\n",
        "      print('[%d, %5d] loss : %.3f' % (epoch+1,i+1,running_loss/2000))\n",
        "      running_loss = 0.0\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pakdQ9rG6xsm",
        "outputId": "b97af59e-0c1d-4962-bc9d-3e1bf242320a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss : 2.145\n",
            "[1,  4000] loss : 1.750\n",
            "[1,  6000] loss : 1.564\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**위 코드는 딥러닝 실행의 표준 코드입니다**\n",
        "\n",
        "**아래는 딥러닝_학습의 전체 흐름입니다**\n",
        "\n",
        "1. 데이터 가져오기, 전처리 하기, 배치화하기\n",
        "\n",
        "2. criterion(loss구하는법), opimizer(가중치매개변수 업데이트하는법) 설정, 초기화\n",
        "\n",
        "3. 만들어놓은 Net에 배치화된 데이터 넣기. ouput 산출\n",
        "\n",
        "4. criterion을 통해 ouput과 정답 label 비교. **단일 스칼라값 형태의 loss 산출**\n",
        "\n",
        "5. loss 기준의 backward 계산(미분값 계산)\n",
        "\n",
        "6. 미분 계산값(loss함수에 대한 가중치 매개변수의 기울기)을 토대로 optimizer를 통해 가중치 매개변수 업데이트\n",
        "\n",
        "7. 출력을 위해 loss 값 누적 & 결과값 산출\n",
        "\n",
        "8. 반복( 입력 데이터의 각 배치가 모두 끝날때까지)\n",
        "\n",
        "9. 반복을 반복(epoch)\n",
        "\n",
        "⏰batch : 데이터를 batch로 묶는다.  \n",
        "\n",
        "ex) 10개의 데이터를 2 크기의 batch로 묶는다. --> 전체 데이터는 5개의 batch로 구성된다\n",
        "\n",
        "⏰epoch : 전체 데이터를 몇번 반복해서 보느냐 \n",
        "\n",
        "ex)5개의 batch로 이루어진 데이터를 한바퀴 본다 --> 1 epoch\n",
        "\n",
        "\n",
        "ex)5개의 batch로 이루어진 데이터를 10바퀴 반복해서 본다 --> 10 epoch"
      ],
      "metadata": {
        "id": "R90Q5KLwdzb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the trained model**\n",
        "\n"
      ],
      "metadata": {
        "id": "a4IBNNlEkqS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#앞서 힘들게 계산한  loss값들을 다시 또 안돌리려면 저장이 필요하다\n",
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(),PATH)\n",
        "#참고로 model save는 적재적소에 가능함. 위의 학습코드에서 3epoch일때 가장 적합한 loss가 나올수 있음\n",
        "#그때 조건문을 걸어 바로 save하게 코드구현이 가능함"
      ],
      "metadata": {
        "id": "ZHwYTgec763e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the pre-trained model**"
      ],
      "metadata": {
        "id": "Mmf2xoullLk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql2eQsjRk7wo",
        "outputId": "fc6e7dee-8850-481c-d3ba-186721ed2d8a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**이제 테스트해보자!!**"
      ],
      "metadata": {
        "id": "3PiQDSXfnEUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad(): # gradient 업데이트 기능을 안하면서 하겠다는 의미\n",
        "  for data in testloader:\n",
        "    images,labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1) #torch.max(outputs.data,1)을 하게 되면 (,2)과 같은 1차원 튜플값이 나온다.\n",
        "    #참고로 torch.max는 argmax와 같은 역할임. batch내의 각 데이터마다 최댓값(ex. 0.8 원핫인코딩.)인 인덱스를 리턴. \n",
        "    #그래서 ,을 무시하기 위해 언더스코어 사용\n",
        "    total +=  labels.size(0)\n",
        "    correct += (predicted == labels).sum().item() #같으면 맞는거다. 이 맞는거의 총합 sum. \n",
        "print('Accuracy of the network on the 10000 test images : %d %%' %(100*correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw4M16sllUMI",
        "outputId": "94c94fcd-f98e-48f4-a44a-c794737387d3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images : 44 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⏰python에서 _(언더스코어)의 의미\n",
        "\n",
        "1. 마지막으로 실행된 결과값 저장 (in 인터프리터)\n",
        "\n",
        "    ex) 10을 쓰고 enter 했다면 다음 쉘에서 _를 치고 enter하면 10이 나옴\n",
        "\n",
        "2. **값을 무시하고 싶은 경우**\n",
        "\n",
        "    ex) x, _, y = (1,2,3) ---> #x=1, y=3\n",
        "\n",
        "\n",
        "3. 특별한 의미의 네이밍을 하는 경우\n",
        "\n",
        "    private 클래스/함수/변수/매서드를 선언할때\n",
        "\n",
        "    ex) class _Base: #private 클래스\n",
        "\n",
        "    def __init__  \n",
        "\n",
        "    def _double #private 매서드"
      ],
      "metadata": {
        "id": "BOopjffepICk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지처리는 사실 위와 같은 CPU연산로 하면 엄청나게 느리고 오래걸림\n",
        "\n",
        "GPU연산으로 하면 훨씬 효율적이다..! 이는 다음시간에"
      ],
      "metadata": {
        "id": "ItnlWd9WyL6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CcYwPrDnnwf7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}